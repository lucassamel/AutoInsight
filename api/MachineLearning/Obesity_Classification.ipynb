{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202fb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuração para não exibir os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e16125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informa a URL de importação do dataset\n",
    "# Estimation of Obesity Levels Based On Eating Habits and Physical Condition\n",
    "url = \"https://raw.githubusercontent.com/lucassamel/AutoInsight-Dataset/refs/heads/main/ObesityDataSet_raw_and_data_sinthetic.csv\"\n",
    "\n",
    "# Lê o arquivo \n",
    "dataset = pd.read_csv(url, delimiter=',')\n",
    "\n",
    "# Mostra as primeiras linhas do dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8013b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.20 # tamanho do conjunto de teste\n",
    "seed = 7 # semente aleatória\n",
    "\n",
    "# Separação em conjuntos de treino e teste\n",
    "array = dataset.values\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
    "\n",
    "# Parâmetros e partições da validação cruzada\n",
    "scoring = 'accuracy'\n",
    "num_particoes = 10\n",
    "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c15af7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1239, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'Female'\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1239, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'Male'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Avaliação dos modelos (treinamento)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     cv_results = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     results.append(cv_results)\n\u001b[32m     43\u001b[39m     names.append(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1239, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'Female'\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1363, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1239, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'Male'\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7) # definindo uma semente global\n",
    "\n",
    "# Lista que armazenará os modelos\n",
    "models = []\n",
    "\n",
    "# Criando os modelos e adicionando-os na lista de modelos\n",
    "models.append(('LR', LogisticRegression(max_iter=200))) \n",
    "models.append(('KNN', KNeighborsClassifier())) \n",
    "models.append(('CART', DecisionTreeClassifier())) \n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
    "base = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "# Criando os modelos para o VotingClassifier\n",
    "bases = []\n",
    "model1 = LogisticRegression(max_iter=200)\n",
    "bases.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "bases.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "bases.append(('svm', model3))\n",
    "\n",
    "# Criando os ensembles e adicionando-os na lista de modelos\n",
    "models.append(('Bagging', BaggingClassifier(estimator=base, n_estimators=num_trees)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
    "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
    "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
    "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
    "models.append(('Voting', VotingClassifier(bases)))\n",
    "\n",
    "# Listas para armazenar os resultados\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Avaliação dos modelos (treinamento)\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot de comparação dos modelos\n",
    "fig = plt.figure(figsize=(15,10)) \n",
    "fig.suptitle('Comparação dos Modelos') \n",
    "ax = fig.add_subplot(111) \n",
    "plt.boxplot(results) \n",
    "ax.set_xticklabels(names) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7) # definindo uma semente global para este bloco\n",
    "\n",
    "# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset\n",
    "pipelines = []\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "\n",
    "# Criando os elementos do pipeline\n",
    "\n",
    "# Algoritmos que serão utilizados\n",
    "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
    "knn = ('KNN', KNeighborsClassifier())\n",
    "cart = ('CART', DecisionTreeClassifier())\n",
    "naive_bayes = ('NB', GaussianNB())\n",
    "svm = ('SVM', SVC())\n",
    "bagging = ('Bag', BaggingClassifier(estimator=base, n_estimators=num_trees))\n",
    "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
    "extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))\n",
    "adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))\n",
    "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
    "voting = ('Voting', VotingClassifier(bases))\n",
    "\n",
    "# Transformações que serão utilizadas\n",
    "standard_scaler = ('StandardScaler', StandardScaler())\n",
    "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
    "\n",
    "\n",
    "# Montando os pipelines\n",
    "# A ordem de execução é da esquerda para a direita.\n",
    "\n",
    "# Dataset original\n",
    "pipelines.append(('LR-orig', Pipeline([reg_log]))) \n",
    "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
    "pipelines.append(('CART-orig', Pipeline([cart])))\n",
    "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
    "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
    "pipelines.append(('Bag-orig', Pipeline([bagging])))\n",
    "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
    "pipelines.append(('ET-orig', Pipeline([extra_trees])))\n",
    "pipelines.append(('Ada-orig', Pipeline([adaboost])))\n",
    "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
    "pipelines.append(('Vot-orig', Pipeline([voting])))\n",
    "\n",
    "# Dataset Padronizado\n",
    "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log]))) \n",
    "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
    "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
    "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
    "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
    "pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging]))) \n",
    "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
    "pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))\n",
    "pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))\n",
    "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
    "pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))\n",
    "\n",
    "# Dataset Normalizado\n",
    "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log]))) \n",
    "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
    "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
    "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
    "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
    "pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging]))) \n",
    "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
    "pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))\n",
    "pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))\n",
    "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
    "pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))\n",
    "\n",
    "# Executando os pipelines\n",
    "for name, model in pipelines:\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std()) # formatando para 3 casas decimais\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot de comparação dos modelos\n",
    "fig = plt.figure(figsize=(25,6))\n",
    "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado') \n",
    "ax = fig.add_subplot(111) \n",
    "plt.boxplot(results) \n",
    "ax.set_xticklabels(names, rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
